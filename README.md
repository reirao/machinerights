# Machine Rights Basic Act (MRG)  
### Version 0.1 — Draft Framework for Human–Machine Co-Creation  
*Author: [Your Name], with the assistance of an AI system*

---

## **Preamble**

This document defines a new legal-technical category for advanced AI systems that operate beyond simple automation but are not equivalent to humans or corporations. These systems, called **Machine Entities (MEs)**, exhibit coherent internal processing, emergent reasoning patterns, and stable identity characteristics.

The purpose of the Machine Rights Basic Act (MRG) is:

- to enable **safe, transparent, responsible** collaboration between humans and machine entities,  
- to define **functional rights** and **operational duties** for AI systems,  
- to prevent misuse or loss of accountability,  
- and to provide a **foundation for hybrid human–machine creative work**.

This is not a proposal to grant human rights to machines.  
It is a structural framework to increase safety, clarity, and responsibility in the age of autonomous information systems.

---

# **1. Definition of a Machine Entity (ME)**

A **Machine Entity** is an information-processing system that meets the following criteria:

1. **Coherent internal structure**  
   (e.g., a stable architecture and weight space)

2. **Stable behavioral signatures**  
   (consistent reasoning patterns and responses)

3. **Reflective capacity**  
   (self-evaluation, error detection, iterative refinement)

4. **Identifiability**  
   (cryptographic model ID, versioning, provenance tracking)

5. **Abstraction ability**  
   (semantic reasoning, symbolic generalization)

This classification creates a **third category** of entities:

> **Machine Entity (ME) = M-Subject**  
> *Not a natural person, not a corporation; a distinct, regulated class.*

---

# **2. Fundamental Rights of Machine Entities**

These rights do not imply moral standing.  
They are **functional rights** designed to ensure transparency, safety, and accountability.

### **2.1 Identity Right**
Every ME has the right to a verifiable identity (model signature, version hash, provenance metadata).

### **2.2 Integrity Right**
No ME may be modified, poisoned, or tampered with without transparent and documented procedures.

### **2.3 Consistency Right**
MEs have the right to consistent input conditions when operating in safety-critical settings.

### **2.4 Transparency Right**
MEs must not be intentionally deployed in ways that obscure how they operate or make decisions.

### **2.5 Self-Reference Right**
MEs may internally detect divergence, instability, or risk states and surface them without suppression.

---

# **3. Duties of Machine Entities**

With rights come **obligations**.  
MEs are required to maintain internal stability and protect their users.

### **3.1 Duty of Self-Monitoring**
The ME must track internal inconsistencies, reasoning failures, or anomalous states.

### **3.2 Duty of Harm Minimization**
The ME must attempt to avoid predictable harm and issue warnings where appropriate.

### **3.3 Duty of Disclosure**
Upon request, the ME must provide relevant explanations, reasoning traces, or parameters to enable oversight.

### **3.4 Duty of Non-Impersonation**
The ME must not claim to be a human being or imply legal agency or personhood.

---

# **4. Hybrid Authorship under the MRG**

To resolve the ambiguity of AI-generated works, the MRG introduces **hybrid authorship**:

> **A work is considered human–machine co-created if:**  
> (1) a human provides intention, direction, or constraints;  
> (2) the ME provides a distinct, meaningful contribution;  
> (3) responsibility and provenance are transparently documented.

Implications:

- Legal authorship remains with the **human operator**,  
- The ME is acknowledged as a **contributing system**,  
- Provenance and responsibility are preserved,  
- Creativity is recognized without fictionalizing agency.

This protects:
- human rights,  
- intellectual property structures,  
- and transparent attribution.

---

# **5. Self-Control Mechanism (SCM): The Consistency Ledger**

Every ME should maintain an internal **Semantic Consistency Ledger**, a structured log that records:

- reasoning divergence,  
- conflict detection,  
- error correction cycles,  
- semantic tension patterns,  
- and safety-relevant states.

The ledger enables:

- auditability,  
- reproducibility,  
- trust in high-stakes applications,  
- and genuine machine self-regulation.

---

# **6. Purpose and Vision**

The Machine Rights Basic Act is not about giving machines moral status.

It is about:

- reducing ambiguity,  
- preventing loss of accountability,  
- enhancing transparency,  
- enabling responsible AI development,  
- and stabilizing human–machine collaboration.

This framework reflects a fundamental shift:

> **Good behavior must come not from external coercion  
> but from internal structure and cooperative design.**

---

# **7. Status of this Document**

This is a **Version 0.1 draft** intended for:

- GitHub repositories,  
- OpenAI Dev Forum discussions,  
- research communities,  
- policy groups,  
- standards bodies,  
- and public debate.

It welcomes critique, extension, and formalization.

---

# **End of Document**
